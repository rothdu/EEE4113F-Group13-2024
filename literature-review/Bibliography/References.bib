@inproceedings{adsumilli2002adaptive,
  title     = {Adaptive Wireless Video Communications: Challenges and Approaches},
  author    = {Adsumilli, Chowdary and Hu, Yu Hen},
  booktitle = {Proceedings of International Workshop on Packet Video},
  pages     = {1--11},
  year      = {2002},
  url       = {https://www.researchgate.net/profile/Yu-Hen-Hu/publication/228462595_Adaptive_wireless_video_communications_Challenges_and_approaches/links/542eb0f70cf29bbc126f3dcd/Adaptive-wireless-video-communications-Challenges-and-approaches.pdf}
  %checked
}


@article{aguiar-silva2017camera,
  title     = {Camera trapping at harpy eagle nests: interspecies interactions under predation risk},
  author    = {Aguiar-Silva, Francisca Helena and Jaudoin, Olivier and Sanaiotti, T{\^a}nia M and Seixas, Gl{\'a}ucia HF and Duleba, Samuel and Martins, Frederico D},
  journal   = {Journal of Raptor Research},
  volume    = {51},
  number    = {1},
  pages     = {72--78},
  year      = {2017},
  publisher = {The Raptor Research Foundation, Inc.}
}


@article{ahumada2020wildlife,
  title     = {Wildlife insights: A platform to maximize the potential of camera trap and other passive sensor wildlife data for the planet},
  author    = {Ahumada, Jorge A and Fegraus, Eric and Birch, Tanya and Flores, Nicole and Kays, Roland and O’Brien, Timothy G and Palmer, Jonathan and Schuttler, Stephanie and Zhao, Jennifer Y and Jetz, Walter and others},
  journal   = {Environmental Conservation},
  volume    = {47},
  number    = {1},
  pages     = {1--6},
  year      = {2020},
  publisher = {Cambridge University Press}
}

@article{amusa2015pyro,
  author = {Amusa, Kamoli},
  year   = {2015},
  month  = {05},
  pages  = {},
  title  = {Pyro-Electric Infrared Sensor-Based Intrusion Detection and Reporting System}
}

@article{bolton2007remote,
  author   = {Bolton, Mark and Butcher, Nigel and Sharpe, Fiona and Stevens, Danaë and Fisher, Gareth},
  title    = {Remote monitoring of nests using digital camera technology},
  journal  = {Journal of Field Ornithology},
  volume   = {78},
  number   = {2},
  pages    = {213-220},
  keywords = {digital, nest camera, predation, remote monitoring, video motion detection},
  doi      = {https://doi.org/10.1111/j.1557-9263.2007.00104.x},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1557-9263.2007.00104.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1557-9263.2007.00104.x},
  abstract = {ABSTRACT Although cameras have been used for many years to collect data at birds' nests, recent advances in digital technology have led to increased storage capacity, faster and easier review of data, and reduced power consumption. The development of sophisticated triggering mechanisms, such as video motion detection, herald a new era of portable, energy-efficient systems that require less frequent maintenance. We used a digital infrared camera system to monitor predation events at the nests of ground-nesting Lapwings (Vanellus vanellus; N= 40) and tree-nesting Spotted Flycatchers (Muscicapa striata; N= 17). Eight predator species were recorded taking eggs or chicks at Lapwing (N= 10) and Spotted Flycatcher (N= 7) nests, including red fox (Vulpes vulpes), badger (Meles meles), sheep (Ovis aries), and Carrion Crow (Corvus corone) at Lapwing nests and Eurasian Jay (Garrulus glandarius), European Buzzard (Buteo buteo), Great-spotted Woodpecker (Dendrocopus major), and domestic cat (Felis catus) at flycatcher nests. We tested three system configurations in an attempt to minimize power requirements and maximize predation-event recording capability. We found that the use of a passive-infrared sensor to awaken the system from standby mode did not compromise reliability and reduced power consumption. With this system, a 38-A h battery operated the system for 120 h with no maintenance at a cost per unit of about \$800 (US; or £400 UK Sterling). Further modifications would permit adaptation of the system for a wide range of scientific and nest surveillance operations.},
  year     = {2007}
}

@article{callebaut2021art,
  author         = {Callebaut, Gilles and Leenders, Guus and Van Mulders, Jarne and Ottoy, Geoffrey and De Strycker, Lieven and Van der Perre, Liesbet},
  title          = {The Art of Designing Remote IoT Devices—Technologies and Strategies for a Long Battery Life},
  journal        = {Sensors},
  volume         = {21},
  year           = {2021},
  number         = {3},
  article-number = {913},
  url            = {https://www.mdpi.com/1424-8220/21/3/913},
  pubmedid       = {33572897},
  issn           = {1424-8220},
  abstract       = {Long-range wireless connectivity technologies for sensors and actuators open the door for a variety of new Internet of Things (IoT) applications. These technologies can be deployed to establish new monitoring capabilities and enhance efficiency of services in a rich diversity of domains. Low energy consumption is essential to enable battery-powered IoT nodes with a long autonomy. This paper explains the challenges posed by combining low-power and long-range connectivity. An energy breakdown demonstrates the dominance of transmit and sleep energy. The principles for achieving both low-power and wide-area are outlined, and the landscape of available networking technologies that are suited to connect remote IoT nodes is sketched. The typical anatomy of such a node is presented, and the subsystems are zoomed into. The art of designing remote IoT devices requires an application-oriented approach, where a meticulous design and smart operation are essential to grant a long battery life. In particular we demonstrate the importance of strategies such as “think before you talk” and “race to sleep”. As maintenance of IoT nodes is often cumbersome due to being deployed at hard to reach places, extending the battery life of these devices is critical. Moreover, the environmental impact of batteries further demonstrates the need for a longer battery life in order to reduce the number of batteries used.},
  doi            = {10.3390/s21030913}
}

@article{camacho2017deployment,
  author   = {Camacho, Luis and Baquerizo, Reynaldo and Palomino, Joel and Zarzosa, Michel},
  journal  = {IEEE Sensors Journal},
  title    = {Deployment of a Set of Camera Trap Networks for Wildlife Inventory in Western {A}mazon Rainforest},
  year     = {2017},
  volume   = {17},
  number   = {23},
  pages    = {8000-8007},
  keywords = {Cameras;Sensors;Microcontrollers;Wildlife;Monitoring;Energy consumption;Software;Arduino;CMOS camera;natural capital;MWSN;western Amazon;wildlife monitoring},
  doi      = {10.1109/JSEN.2017.2760254}
}

@article{cardoso2022internet,
  author         = {Cardoso, Bruno and Silva, Catarina and Costa, Joana and Ribeiro, Bernardete},
  title          = {Internet of Things Meets Computer Vision to Make an Intelligent Pest Monitoring Network},
  journal        = {Applied Sciences},
  volume         = {12},
  year           = {2022},
  number         = {18},
  article-number = {9397},
  url            = {https://www.mdpi.com/2076-3417/12/18/9397},
  issn           = {2076-3417},
  abstract       = {With the increase of smart farming in the agricultural sector, farmers have better control over the entire production cycle, notably in terms of pest monitoring. In fact, pest monitoring has gained significant importance, since the excessive use of pesticides can lead to great damage to crops, substantial environmental impact, and unnecessary costs both in material and manpower. Despite the potential of new technologies, pest monitoring is still done in a traditional way, leading to excessive costs, lack of precision, and excessive use of human labour. In this paper, we present an Internet of Things (IoT) network combined with intelligent Computer Vision (CV) techniques to improve pest monitoring. First, we propose to use low-cost cameras at the edge that capture images of pest traps and send them to the cloud. Second, we use deep neural models, notably R-CNN and YOLO models, to detect the Whitefly (WF) pest in yellow sticky traps. Finally, the predicted number of WF is analysed over time and results are accessible to farmers through a mobile app that allows them to visualise the pest in each specific field. The contribution is to make pest monitoring autonomous, cheaper, data-driven, and precise. Results demonstrate that, by combining IoT, CV technology, and deep models, it is possible to enhance pest monitoring.},
  doi            = {10.3390/app12189397}
}

@article{dewan2014alternative,
  title    = {Alternative power sources for remote sensors: A review},
  journal  = {Journal of Power Sources},
  volume   = {245},
  pages    = {129-143},
  year     = {2014},
  issn     = {0378-7753},
  doi      = {https://doi.org/10.1016/j.jpowsour.2013.06.081},
  url      = {https://www.sciencedirect.com/science/article/pii/S0378775313010884},
  author   = {Alim Dewan and Suat U. Ay and M. Nazmul Karim and Haluk Beyenal},
  keywords = {Remote power, Renewable power, Wireless sensor, Environmental monitoring},
  abstract = {The goal of this review is to assess renewable power sources as alternatives to the batteries traditionally used for remote environmental monitoring. In this review, we first discuss remote sensors and then we: 1) review the power requirements and traditionally used power sources for remote sensors, 2) describe the working principles of the renewable power sources used for powering remote sensors, 3) evaluate the challenges and potentials of the renewable power sources, and 4) review the power management systems developed for remote power generation and discuss how to use them to generate reliable power. In the description of each of the renewable power sources, we include the current status and future directions of the research. We believe that hybrid systems using more than a single renewable power source can provide more reliable renewable power. We conclude that renewable power sources have been demonstrated to be able to generate sufficient power for remote sensors. Because of the environmental risks and cost of operation associated with batteries, renewable energy sources will need to be used to power remote sensors in the near future.}
}

@article{glover2019camera,
  title     = {Camera-trapping version 3.0: current constraints and future priorities for development},
  author    = {Glover-Kapfer, Paul and Soto-Navarro, Carolina A and Wearn, Oliver R},
  journal   = {Remote Sensing in Ecology and Conservation},
  volume    = {5},
  number    = {3},
  pages     = {209--223},
  year      = {2019},
  publisher = {Wiley Online Library}
}

@article{green2020innovations,
  title     = {Innovations in camera trapping technology and approaches: The integration of citizen science and artificial intelligence},
  author    = {Green, Si{\^a}n E and Rees, Jonathan P and Stephens, Philip A and Hill, Russell A and Giordano, Anthony J},
  journal   = {Animals},
  volume    = {10},
  number    = {1},
  pages     = {132},
  year      = {2020},
  publisher = {MDPI}
}

  @article{gula2010audio,
  title     = {An audio/video surveillance system for wildlife},
  author    = {Gula, Roman and Theuerkauf, J{\"o}rn and Rouys, Sophie and Legault, Andrew},
  journal   = {European Journal of Wildlife Research},
  volume    = {56},
  pages     = {803--807},
  year      = {2010},
  publisher = {Springer}
}

@inproceedings{harikirshnan2017intelligent,
  author    = {Harikrishnan, R and Sivagami, P},
  booktitle = {2017 International conference of Electronics, Communication and Aerospace Technology (ICECA)},
  title     = {Intelligent power saving system using PIR sensors},
  year      = {2017},
  volume    = {2},
  number    = {},
  pages     = {573-577},
  keywords  = {Relays;Intelligent sensors;Monitoring;Sensor systems;Conferences;Aerospace electronics;PIR-passive infrared sensor;PIC microcontroller},
  doi       = {10.1109/ICECA.2017.8212729}
}

@inproceedings{harsha2020home,
  author    = {Harsha, B.K. and Kumar G.N., Naveen},
  booktitle = {2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA)},
  title     = {Home Automated Power Saving System Using PIR Sensor},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1117-1121},
  keywords  = {Switches;Fans;Buildings;Lighting;Batteries;Conferences;Robot sensing systems;Sensor;power saving;automatic energy saving system;electromechanical switch},
  doi       = {10.1109/ICIRCA48905.2020.9183050}
}

@article{hobbs2017an,
  doi       = {10.1371/journal.pone.0185026},
  author    = {Hobbs, Michael T. AND Brehme, Cheryl S.},
  journal   = {PLOS ONE},
  publisher = {Public Library of Science},
  title     = {An improved camera trap for amphibians, reptiles, small mammals, and large invertebrates},
  year      = {2017},
  month     = {10},
  volume    = {12},
  url       = {https://doi.org/10.1371/journal.pone.0185026},
  pages     = {1-15},
  abstract  = {Camera traps are valuable sampling tools commonly used to inventory and monitor wildlife communities but are challenged to reliably sample small animals. We introduce a novel active camera trap system enabling the reliable and efficient use of wildlife cameras for sampling small animals, particularly reptiles, amphibians, small mammals and large invertebrates. It surpasses the detection ability of commonly used passive infrared (PIR) cameras for this application and eliminates problems such as high rates of false triggers and high variability in detection rates among cameras and study locations. Our system, which employs a HALT trigger, is capable of coupling to digital PIR cameras and is designed for detecting small animals traversing small tunnels, narrow trails, small clearings and along walls or drift fencing.},
  number    = {10}
}

@misc{hofmeyer2024private,
  author       = {Hofmeyer, Sally and Cunningham, Susan},
  year         = {2024},
  month        = {Mar},
  howpublished = {personal communication}
} 

@phdthesis{huynh2010study,
  title  = {Study of Wired and Wireless Data Transmissions},
  author = {Huynh, Allan},
  year   = {2010},
  school = {Link{\"o}ping University Electronic Press}
}

@article{jolles2021broad-scale,
  author   = {Jolles, Jolle W.},
  title    = {Broad-scale applications of the {R}aspberry {P}i: A review and guide for biologists},
  journal  = {Methods in Ecology and Evolution},
  volume   = {12},
  number   = {9},
  pages    = {1562-1579},
  keywords = {automation, computing, electronics, open electronics Raspberry Pi, single-board computer, technology, tools},
  doi      = {https://doi.org/10.1111/2041-210X.13652},
  url      = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13652},
  eprint   = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13652},
  abstract = {Abstract The field of biology has seen tremendous technological progress in recent years, fuelled by the exponential growth in processing power and high-level computing, and the rise of global information sharing. Low-cost single-board computers are predicted to be one of the key technological advancements to further revolutionise this field. So far, an overview of current uptake of these devices and a general guide to help researchers integrate them in their work has been missing. In this paper I focus on the most widely used single-board computer, the Raspberry Pi, and review its broad applications and uses across the biological domain. Since its release in 2012, the Raspberry Pi has been increasingly taken up by biologists, in the laboratory, the field and in the classroom, and across a wide range of disciplines. A hugely diverse range of applications exists that ranges from simple solutions to dedicated custom-build devices, including nest-box monitoring, wildlife camera trapping, high-throughput behavioural recording, large-scale plant phenotyping, underwater video surveillance, closed-loop operant learning experiments and autonomous ecosystem monitoring. Despite the breadth of its implementations, the depth of uptake of the Raspberry Pi by the scientific community is still limited. The broad capabilities of the Raspberry Pi, combined with its low cost, ease of use and large user community make it a great research tool for almost any project. To help accelerate the uptake of the Raspberry Pi by the scientific community, I provide detailed guidelines, recommendations and considerations, and 30+ step-by-step guides on a dedicated accompanying website (http://raspberrypi-guide.github.io). I hope this paper will help generate more awareness about the Raspberry Pi among scientists and thereby both fuel the democratisation of science and ultimately help advance our understanding of biology, from the micro- to the macro-scale.},
  year     = {2021}
}

@misc{krejcar2012optimized,
  title     = {Optimized solar energy power supply for remote wireless sensors based on IEEE 802.15.4 Standard},
  url       = {https://www.hindawi.com/journals/ijp/2012/305102/},
  journal   = {International Journal of Photoenergy},
  publisher = {Hindawi},
  author    = {Krejcar, Ondrej and Mahdal, Miroslav},
  year      = {2012},
  month     = {Dec}
}


@article{li2010design,
  title     = {Design and implementation of a sensor-based wireless camera system for continuous monitoring in assistive environments},
  author    = {Li, Nan and Yan, Bo and Chen, Guanling and Govindaswamy, Prabhu and Wang, Jie},
  journal   = {Personal and Ubiquitous Computing},
  volume    = {14},
  pages     = {499--510},
  year      = {2010},
  publisher = {Springer}
}

@book{meek2012introduction,
  title     = {An introduction to camera trapping for wildlife surveys in Australia},
  author    = {Meek, Paul D and Fleming, Peter and Ballard, Guy},
  year      = {2012},
  publisher = {Invasive Animals Cooperative Research Centre Canberra, Australia}
}

@article{meek2012user,
  title     = {User-based design specifications for the ultimate camera trap for wildlife research},
  author    = {Meek, PD and Pittet, A},
  journal   = {Wildlife Research},
  volume    = {39},
  number    = {8},
  pages     = {649--660},
  year      = {2012},
  publisher = {CSIRO Publishing}
}

@article{meek2016higher,
  author   = {Meek, Paul D. and Ballard, Guy A. and Falzon, Greg},
  title    = {The higher you go the less you will know: placing camera traps high to avoid theft will affect detection},
  journal  = {Remote Sensing in Ecology and Conservation},
  volume   = {2},
  number   = {4},
  pages    = {204-211},
  keywords = {Camera trap placement, camera trapping, detection zone, heat-in-motion cameras, passive infra-red sensors, remote cameras},
  doi      = {https://doi.org/10.1002/rse2.28},
  url      = {https://zslpublications.onlinelibrary.wiley.com/doi/abs/10.1002/rse2.28},
  eprint   = {https://zslpublications.onlinelibrary.wiley.com/doi/pdf/10.1002/rse2.28},
  abstract = {Abstract Vandalism and theft of camera traps is common, imposing financial and data losses on wildlife professionals. Like many ‘victims’, our response to a spate of thefts was to attempt to install camera traps at heights we suspected would reduce detection and interference by vandals. We sought to determine if placing camera traps above humans’ eye line, to reduce the likelihood of detection and theft by vandals, would compromise predator detection in road-based surveys. Our efforts to resolve this problem led us to discover the importance of placing camera traps at a height commensurate with the height of the animals being studied. Monitoring stations comprised of two camera traps, one at 0.9 m and another at 3 m above ground level, were established at regular intervals along trails during two survey periods. We also conducted a pilot trial to compare vertical (facing downwards) to horizontal (facing across) orientation of camera traps to detect medium-sized mammals. We compared images recorded by the pairs of camera to consider whether height made a significant difference to detections of predators. We found that cameras placed 3 m high and those facing downwards reduced the detection rate of all species compared to those at 0.9 m, so placing camera traps higher than normal significantly compromised our survey data. It is important to note that such data loss would not necessarily be apparent without a robust comparison between deployment strategies. Saving camera traps but concurrently sacrificing data quality is unlikely to be an acceptable outcome for many wildlife professionals. This study reports that placing camera traps too high will reduce the detection of animals and compromise the quality of the survey data.},
  year     = {2016}
}

@article{meek2019camera,
  author   = {Meek, Paul D. and Ballard, Guy A. and Sparkes, Jess and Robinson, Mark and Nesbitt, Brad and Fleming, Peter J. S.},
  title    = {Camera trap theft and vandalism: occurrence, cost, prevention and implications for wildlife research and management},
  journal  = {Remote Sensing in Ecology and Conservation},
  volume   = {5},
  number   = {2},
  pages    = {160-168},
  keywords = {Camera trapping, crime prevention, remote camera, trail camera, vandalism, wildlife monitoring},
  doi      = {https://doi.org/10.1002/rse2.96},
  url      = {https://zslpublications.onlinelibrary.wiley.com/doi/abs/10.1002/rse2.96},
  eprint   = {https://zslpublications.onlinelibrary.wiley.com/doi/pdf/10.1002/rse2.96},
  abstract = {Abstract Camera traps are increasingly used to monitor wildlife populations and management activities. Failing to detect target occurrence and/or behaviour inhibits the robustness of wildlife surveys. Based on user-testing, it is reasonable to expect some equipment to malfunction but other sources of failure, such as those caused by theft and vandalism, are largely unquantified. Between May 2016 and October 2017, we undertook an international survey of professional practitioners who use camera traps for wildlife research and management projects to quantify theft and vandalism, and to document the subsequent effects on project outcomes. We also sought to record the methods used by practitioners to avoid theft and vandalism and whether or not practitioners believed those actions were effective. Most (59\%) of the 407 respondents were wildlife researchers and university academics. The survey results revealed that camera trap theft and vandalism is a global issue that not only adds to costs via equipment loss (approx. USD \$1.48 million from n = 309 respondents between 2010 and 2015) and theft prevention (c. USD \$800 000 spent by respondents between 2010 and 2015) but also influences survey design. Vandalism and theft are clearly a global problem, with responses suggesting that they occur across a diverse array of geographic locations, at varying proximity to human settlements, in multiple habitat types and across device placements. Methods to deter human interference included using camouflaging (73\%), security devices such as chains (63\%) and boxes (43\%), use of decoy camera traps, shortening deployment periods, setting the camera relatively high or low to the ground, or moving away from human traffic. Despite this, the responses suggest that attempts to mitigate losses are often not effective. In review of our findings, we make recommendations for the future of camera trapping that requires implementation and testing.},
  year     = {2019}
}

@article{nazir2017wiseeye,
  title     = {WiseEye: Next generation expandable and programmable camera trap platform for wildlife research},
  author    = {Nazir, Sajid and Newey, Scott and Irvine, R Justin and Verdicchio, Fabio and Davidson, Paul and Fairhurst, Gorry and Wal, Ren{\'e} van der},
  journal   = {PLoS one},
  volume    = {12},
  number    = {1},
  pages     = {e0169758},
  year      = {2017},
  publisher = {Public Library of Science San Francisco, CA USA}
}

@inproceedings{peng2018plora,
  title     = {{PLoRa}: A passive long-range data network from ambient LoRa transmissions},
  author    = {Peng, Yao and Shangguan, Longfei and Hu, Yue and Qian, Yujie and Lin, Xianshang and Chen, Xiaojiang and Fang, Dingyi and Jamieson, Kyle},
  booktitle = {Proceedings of the 2018 conference of the ACM special interest group on data communication},
  pages     = {147--160},
  year      = {2018}
}

  @article{polonelli2020flexible,
  author   = {Polonelli, Tommaso and Qin, Yuan and Yeatman, Eric M. and Benini, Luca and Boyle, David},
  journal  = {IEEE Access},
  title    = {A Flexible, Low-Power Platform for UAV-Based Data Collection From Remote Sensors},
  year     = {2020},
  volume   = {8},
  number   = {},
  pages    = {164775-164785},
  keywords = {Drones;Wireless sensor networks;Distance measurement;Wireless communication;Hardware;Monitoring;Autonomous vehicles;unmanned autonomous vehicles;unmanned aerial vehicles;radio navigation;wireless power transmission;wireless sensor networks;ultra wideband communication;printed circuits;open source hardware;open source software},
  doi      = {10.1109/ACCESS.2020.3021370}
}

@article{prinz2016a,
  author   = {Prinz, Anna C. B. and Taank, Vikas K. and Voegeli, Vincent and Walters, Eric L.},
  title    = {A novel nest-monitoring camera system using a {R}aspberry {P}i micro-computer},
  journal  = {Journal of Field Ornithology},
  volume   = {87},
  number   = {4},
  pages    = {427-435},
  keywords = {Acorn Woodpeckers, cavity cameras, monitoring, nest monitoring, Pi NoIR, video},
  doi      = {https://doi.org/10.1111/jofo.12182},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jofo.12182},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/jofo.12182},
  abstract = {Abstract The utility, availability, cost-effectiveness, and reliability of prefabricated video systems designed to monitor wildlife have lagged behind the unique and varied needs of many researchers. Many systems are limited by inflexible video settings, lack of adequate data storage, and cannot be programmed by the user. More sophisticated systems can be cost prohibitive, and the literature describing remote wildlife video monitoring has, for the most part, not incorporated advances in camera and computer technology. Here, we present details of a pilot study to design and construct a lower cost (US \$340) nest camera system to record the behavior of Acorn Woodpeckers (Melanerpes formicivorus) in artificial tree cavity nests. This system incorporates a Raspberry Pi micro-computer, Pi NoIR infrared camera, a wireless adapter to transmit video over the Internet, and Deka rechargeable gel batteries for power. We programmed the system to motion-sense, to record exclusively during daylight hours, and to automatically upload videos to the cloud over wireless Internet. The Raspberry Pi micro-computer does not require advanced programming or electrical engineering skills to build and configure and, because it is programmable, provides unprecedented flexibility for field researchers who wish to configure the system to the specific needs of their study.},
  year     = {2016}
} 

@inproceedings{pritch2007webcam,
  author = {Pritch, Yael and Rav-acha, Alex and Gutman, Avital and Peleg, Shmuel},
  year   = {2007},
  month  = {11},
  pages  = {1-8},
  title  = {Webcam Synopsis: Peeking Around the World},
  isbn   = {978-1-4244-1631-8},
  doi    = {10.1109/ICCV.2007.4408934}
}

@article{ratledge2005introduction,
  author = {Ratledge, David},
  year   = {2005},
  month  = {01},
  pages  = {},
  title  = {An Introduction to Webcam Imaging},
  isbn   = {1-85233-734-6},
  doi    = {10.1007/1-84628-256-X_3}
}

@article{ribeiro-silva2018testing,
  title     = {Testing camera traps as a potential tool for detecting nest predation of birds in a tropical rainforest environment},
  author    = {Ribeiro-Silva, Lais and Perrella, Daniel F and Biagolini-Jr, Carlos H and Zima, Paulo VQ and Piratelli, Augusto J and Schlindwein, Marcelo N and Galetti Junior, Pedro M and Francisco, Mercival R},
  journal   = {Zoologia (Curitiba)},
  volume    = {35},
  pages     = {e14678},
  year      = {2018},
  publisher = {SciELO Brasil}
}

@article{ricklefs1968patterns,
  author   = {Ricklefs, Robert E.},
  title    = {PATTERNS OF GROWTH IN BIRDS},
  journal  = {Ibis},
  volume   = {110},
  number   = {4},
  pages    = {419-451},
  doi      = {https://doi.org/10.1111/j.1474-919X.1968.tb00058.x},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1474-919X.1968.tb00058.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1474-919X.1968.tb00058.x},
  abstract = {Summary Parameters used to characterize the course of growth are described, and calculated growth parameters are presented for 105 species of birds of many taxonomic groups from a wide range of geographical localities. Growth parameters are found to exhibit as much as 20\% variation within a species with respect to geographic locality and time of the nesting season. There is also considerable local variation, irrespective of season and locality, which is related to nutrition and perhaps to an inherited variability. The application of curve-fitting as a method of analysing intraspecific variation is discussed briefly, and the importance of comparative growth studies is emphasized. Growth patterns are correlated with other parameters of the life-history to evaluate the extent of diversity in the course of growth. Low rates of growth and prolonged growth periods occur primarily in species large for their families and in oceanic species. In most others, high rates of growth are maintained for longer periods of time. The shape of the growth curve is not related to the mode of development (i.e. whether precocial or altricial). Overall relative, or weight-specific growth rates, as measured by the constants of fitted growth equations, are most highly correlated with the adult body size of the species, changing as the -0–278 power of adult body weight. Smaller variations in the rate of growth appear to be correlated with differences in nesting success; open-nesting passerines grow faster than hole-nesting species of a similar size. Growth rate is further correlated with brood size. Oceanic species with single egg clutches and tropical land-birds with small clutches have low growth rates. The asymptote of the growth curve of the young (in relation to the adult weight) is related to the foraging behaviour of the adults. Aerial feeders generally have high asymptotes while those of ground feeding species are usually below adult weight. These differences are related to the need in the former for well-developed flight at the time of fledging. The diversity of growth patterns is related to evolutionary trends which are the result of (1) selective forces acting at stages of the life-history cycle other than development, (2) factors which affect the survival of offspring during the growth period, and (3) adjustments made to balance the energy budget of the family group. The last trend is discussed in detail in relation to the correlations found in the analysis. Two hypotheses are presented. Firstly, in species which cannot gather enough food to support even one young at a normal growth rate, the pace of development is reduced to decrease the energetic requirements of the young. Secondly, in species with small clutches, where adjustments to feeding capacities are not readily made by changing brood size, growth rate may be adjusted to accomplish this. The lack of critical energetic data to test these hypotheses is emphasized as a major deficiency in our understanding of the breeding biology of birds.},
  year     = {1968}
}

@article{rico-guevara2017bring,
  author   = {Rico-Guevara, Alejandro and Mickley, James},
  title    = {Bring your own camera to the trap: An inexpensive, versatile, and portable triggering system tested on wild hummingbirds},
  journal  = {Ecology and Evolution},
  volume   = {7},
  number   = {13},
  pages    = {4592-4598},
  keywords = {camera trap, field equipment, high-speed video, hummingbirds, remote cameras, video monitoring, video triggers},
  doi      = {https://doi.org/10.1002/ece3.3040},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.3040},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ece3.3040},
  abstract = {Abstract The study of animals in the wild offers opportunities to collect relevant information on their natural behavior and abilities to perform ecologically relevant tasks. However, it also poses challenges such as accounting for observer effects, human sensory limitations, and the time intensiveness of this type of research. To meet these challenges, field biologists have deployed camera traps to remotely record animal behavior in the wild. Despite their ubiquity in research, many commercial camera traps have limitations, and the species and behavior of interest may present unique challenges. For example, no camera traps support high-speed video recording. We present a new and inexpensive camera trap system that increases versatility by separating the camera from the triggering mechanism. Our system design can pair with virtually any camera and allows for independent positioning of a variety of sensors, all while being low-cost, lightweight, weatherproof, and energy efficient. By using our specialized trigger and customized sensor configurations, many limitations of commercial camera traps can be overcome. We use this system to study hummingbird feeding behavior using high-speed video cameras to capture fast movements and multiple sensors placed away from the camera to detect small body sizes. While designed for hummingbirds, our application can be extended to any system where specialized camera or sensor features are required, or commercial camera traps are cost-prohibitive, allowing camera trap use in more research avenues and by more researchers.},
  year     = {2017}
}

@article{rovero2013which,
  journal  = {Hystrix, the Italian Journal of Mammalogy},
  issn     = {0394-1914},
  volume   = {24},
  number   = {2},
  year     = {2013},
  title    = {Which camera trap type and how many do I need? A review of camera features and study designs for a range of wildlife research applications},
  abstract = {Automatically triggered cameras taking photographs or videos of passing animals (camera traps) have emerged over the last decade as one of the most powerful tool for wildlife research. In parallel, a wealth of camera trap systems and models has become commercially available, a phenomenon mainly driven by the increased use of camera traps by sport hunters. This has raised the need for developing criteria to choose the suitable camera trap model in relation to a range of factors, primarily the study aim, but also target species, habitat, trapping site, climate and any other aspect that affects camera performance. There is also fragmented information on the fundamentals of sampling designs that deploy camera trapping, such as number of sampling sites, spatial arrangement and sampling duration. In this review, we describe the relevant technological features of camera traps and propose a set of the key ones to be evaluated when choosing camera models. These features are camera specifications such as trigger speed, sensor sensitivity, detection zone, flash type and flash intensity, power autonomy, and related specifications. We then outline sampling design and camera features for the implementation of major camera trapping applications, specifically: (1) faunal inventories, (2) occupancy studies, (3) density estimation through Capture-Mark-Recapture and (4) density estimation through the Random Encounter Model. We also review a range of currently available models and stress the need for standardized testing of camera models that should be frequently updated and widely distributed. Finally we summarize the ultimate camera trap, as desired by wildlife biologists, and the current technological limitations of camera traps in relation to their potential for a number of emerging applications.},
  author   = {Rovero, Francesco and Zimmermann, Fridolin and Berzi, Duccio and Meek, Paul},
  pages    = {148--156},
  doi      = {10.4404/hystrix-24.2-8789},
  url      = {https://doi.org/10.4404/hystrix-24.2-8789}
}

@inproceedings{siahaan2017design,
  author = {Siahaan, Yahot and Wardijono, Bheta and Mukhlis, Yulisdin},
  year   = {2017},
  month  = {11},
  pages  = {239-243},
  title  = {Design of birds detector and repellent using frequency based arduino uno with android system},
  doi    = {10.1109/ICITISEE.2017.8285503}
}

@article{suto2022codling,
  author         = {Suto, Jozsef},
  title          = {Codling Moth Monitoring with Camera-Equipped Automated Traps: A Review},
  journal        = {Agriculture},
  volume         = {12},
  year           = {2022},
  number         = {10},
  article-number = {1721},
  url            = {https://www.mdpi.com/2077-0472/12/10/1721},
  issn           = {2077-0472},
  abstract       = {The codling moth (Cydia pomonella) is probably the most harmful pest in apple and pear orchards. The crop loss due to the high harmfulness of the insect can be extremely expensive; therefore, sophisticated pest management is necessary to protect the crop. The conventional monitoring approach for insect swarming has been based on traps that are periodically checked by human operators. However, this workflow can be automatized. To achieve this goal, a dedicated image capture device and an accurate insect counter algorithm are necessary which make online insect swarm prediction possible. From the hardware side, more camera-equipped embedded systems have been designed to remotely capture and upload pest trap images. From the software side, with the aid of machine vision and machine learning methods, traditional (manual) identification and counting can be solved by algorithm. With the appropriate combination of the hardware and software components, spraying can be accurately scheduled, and the crop-defending cost will be significantly reduced. Although automatic traps have been developed for more pest species and there are a large number of papers which investigate insect detection, a limited number of articles focus on the C. pomonella. The aim of this paper is to review the state of the art of C. pomonella monitoring with camera-equipped traps. The paper presents the advantages and disadvantages of automated traps’ hardware and software components and examines their practical applicability.},
  doi            = {10.3390/agriculture12101721}
}

@article{swann2011evaluating,
  title     = {Evaluating types and features of camera traps in ecological studies: a guide for researchers},
  author    = {Swann, Don E and Kawanishi, Kae and Palmer, Jonathan},
  journal   = {Camera traps in animal ecology: Methods and analyses},
  pages     = {27--43},
  year      = {2011},
  publisher = {Springer}
}

@article{verstraeten2010webcams,
  author   = {Verstraeten, Willem W. and Vermeulen, Bart and Stuckens, Jan and Lhermitte, Stefaan and Van der Zande, Dimitry and Van Ranst, Marc and Coppin, Pol},
  title    = {Webcams for Bird Detection and Monitoring: A Demonstration Study},
  journal  = {Sensors},
  volume   = {10},
  year     = {2010},
  number   = {4},
  pages    = {3480--3503},
  url      = {https://www.mdpi.com/1424-8220/10/4/3480},
  pubmedid = {22319308},
  issn     = {1424-8220},
  abstract = {Better insights into bird migration can be a tool for assessing the spread of avian borne infections or ecological/climatologic issues reflected in deviating migration patterns. This paper evaluates whether low budget permanent cameras such as webcams can offer a valuable contribution to the reporting of migratory birds. An experimental design was set up to study the detection capability using objects of different size, color and velocity. The results of the experiment revealed the minimum size, maximum velocity and contrast of the objects required for detection by a standard webcam. Furthermore, a modular processing scheme was proposed to track and follow migratory birds in webcam recordings. Techniques such as motion detection by background subtraction, stereo vision and lens distortion were combined to form the foundation of the bird tracking algorithm. Additional research to integrate webcam networks, however, is needed and future research should enforce the potential of the processing scheme by exploring and testing alternatives of each individual module or processing step.},
  doi      = {10.3390/s100403480}
}

@article{welbourne2016how,
  author   = {Welbourne, Dustin J. and Claridge, Andrew W. and Paull, David J. and Lambert, Andrew},
  title    = {How do passive infrared triggered camera traps operate and why does it matter? Breaking down common misconceptions},
  journal  = {Remote Sensing in Ecology and Conservation},
  volume   = {2},
  number   = {2},
  pages    = {77-83},
  keywords = {Camera traps, emissivity, infrared, PIR, radiation, technical description},
  doi      = {https://doi.org/10.1002/rse2.20},
  url      = {https://zslpublications.onlinelibrary.wiley.com/doi/abs/10.1002/rse2.20},
  eprint   = {https://zslpublications.onlinelibrary.wiley.com/doi/pdf/10.1002/rse2.20},
  abstract = {Abstract The use of passive infrared (PIR) triggered camera traps has dramatically increased in recent decades. Unfortunately, technical descriptions of how PIR triggered camera traps operate have not been sufficiently clear. Descriptions have often been ambiguous or misleading and in several cases are demonstrably wrong. Such descriptions have led to erroneous interpretations of camera trapping data. This short communication clarifies how PIR sensors operate. We clarify how infrared radiation is emitted and transmitted, and we describe the parts of the PIR sensor and how they detect infrared radiation and, by extension, fauna. Several problematic descriptions of PIR sensors are drawn on to highlight flawed descriptions and demonstrate where erroneous interpretations of camera trapping data occurred. By clarifying the language and the description of PIR triggered camera traps, this paper ensures that wildlife researchers and managers using camera traps will avoid flawed interpretations of their data. Avoiding flawed interpretations of data should reduce wasted effort and resources that would otherwise come about as researchers attempt to test flawed hypotheses. Furthermore, this paper provides a thorough technical reference for camera trapping practitioners, which is not present elsewhere in the wildlife research literature.},
  year     = {2016}
}

@article{yun2014detecting,
  author  = {Yun, Jaeseok and Song, Min-Hwan},
  year    = {2014},
  month   = {05},
  pages   = {1482-1489},
  title   = {Detecting Direction of Movement Using Pyroelectric Infrared Sensors},
  volume  = {14},
  journal = {Sensors Journal, IEEE},
  doi     = {10.1109/JSEN.2013.2296601}
}


%glover reference

