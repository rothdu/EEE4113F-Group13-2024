@Article{cardoso2022internet,
AUTHOR = {Cardoso, Bruno and Silva, Catarina and Costa, Joana and Ribeiro, Bernardete},
TITLE = {Internet of Things Meets Computer Vision to Make an Intelligent Pest Monitoring Network},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {18},
ARTICLE-NUMBER = {9397},
URL = {https://www.mdpi.com/2076-3417/12/18/9397},
ISSN = {2076-3417},
ABSTRACT = {With the increase of smart farming in the agricultural sector, farmers have better control over the entire production cycle, notably in terms of pest monitoring. In fact, pest monitoring has gained significant importance, since the excessive use of pesticides can lead to great damage to crops, substantial environmental impact, and unnecessary costs both in material and manpower. Despite the potential of new technologies, pest monitoring is still done in a traditional way, leading to excessive costs, lack of precision, and excessive use of human labour. In this paper, we present an Internet of Things (IoT) network combined with intelligent Computer Vision (CV) techniques to improve pest monitoring. First, we propose to use low-cost cameras at the edge that capture images of pest traps and send them to the cloud. Second, we use deep neural models, notably R-CNN and YOLO models, to detect the Whitefly (WF) pest in yellow sticky traps. Finally, the predicted number of WF is analysed over time and results are accessible to farmers through a mobile app that allows them to visualise the pest in each specific field. The contribution is to make pest monitoring autonomous, cheaper, data-driven, and precise. Results demonstrate that, by combining IoT, CV technology, and deep models, it is possible to enhance pest monitoring.},
DOI = {10.3390/app12189397}
}


@ARTICLE{camacho2017deployment,
author={Camacho, Luis and Baquerizo, Reynaldo and Palomino, Joel and Zarzosa, Michel},
journal={IEEE Sensors Journal}, 
title={Deployment of a Set of Camera Trap Networks for Wildlife Inventory in Western {A}mazon Rainforest}, 
year={2017},
volume={17},
number={23},
pages={8000-8007},
keywords={Cameras;Sensors;Microcontrollers;Wildlife;Monitoring;Energy consumption;Software;Arduino;CMOS camera;natural capital;MWSN;western Amazon;wildlife monitoring},
doi={10.1109/JSEN.2017.2760254}
}


@Article{suto2022codling,
AUTHOR = {Suto, Jozsef},
TITLE = {Codling Moth Monitoring with Camera-Equipped Automated Traps: A Review},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {10},
ARTICLE-NUMBER = {1721},
URL = {https://www.mdpi.com/2077-0472/12/10/1721},
ISSN = {2077-0472},
ABSTRACT = {The codling moth (Cydia pomonella) is probably the most harmful pest in apple and pear orchards. The crop loss due to the high harmfulness of the insect can be extremely expensive; therefore, sophisticated pest management is necessary to protect the crop. The conventional monitoring approach for insect swarming has been based on traps that are periodically checked by human operators. However, this workflow can be automatized. To achieve this goal, a dedicated image capture device and an accurate insect counter algorithm are necessary which make online insect swarm prediction possible. From the hardware side, more camera-equipped embedded systems have been designed to remotely capture and upload pest trap images. From the software side, with the aid of machine vision and machine learning methods, traditional (manual) identification and counting can be solved by algorithm. With the appropriate combination of the hardware and software components, spraying can be accurately scheduled, and the crop-defending cost will be significantly reduced. Although automatic traps have been developed for more pest species and there are a large number of papers which investigate insect detection, a limited number of articles focus on the C. pomonella. The aim of this paper is to review the state of the art of C. pomonella monitoring with camera-equipped traps. The paper presents the advantages and disadvantages of automated traps’ hardware and software components and examines their practical applicability.},
DOI = {10.3390/agriculture12101721}
}

@article{jolles2021broad-scale,
author = {Jolles, Jolle W.},
title = {Broad-scale applications of the {R}aspberry {P}i: A review and guide for biologists},
journal = {Methods in Ecology and Evolution},
volume = {12},
number = {9},
pages = {1562-1579},
keywords = {automation, computing, electronics, open electronics Raspberry Pi, single-board computer, technology, tools},
doi = {https://doi.org/10.1111/2041-210X.13652},
url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13652},
eprint = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13652},
abstract = {Abstract The field of biology has seen tremendous technological progress in recent years, fuelled by the exponential growth in processing power and high-level computing, and the rise of global information sharing. Low-cost single-board computers are predicted to be one of the key technological advancements to further revolutionise this field. So far, an overview of current uptake of these devices and a general guide to help researchers integrate them in their work has been missing. In this paper I focus on the most widely used single-board computer, the Raspberry Pi, and review its broad applications and uses across the biological domain. Since its release in 2012, the Raspberry Pi has been increasingly taken up by biologists, in the laboratory, the field and in the classroom, and across a wide range of disciplines. A hugely diverse range of applications exists that ranges from simple solutions to dedicated custom-build devices, including nest-box monitoring, wildlife camera trapping, high-throughput behavioural recording, large-scale plant phenotyping, underwater video surveillance, closed-loop operant learning experiments and autonomous ecosystem monitoring. Despite the breadth of its implementations, the depth of uptake of the Raspberry Pi by the scientific community is still limited. The broad capabilities of the Raspberry Pi, combined with its low cost, ease of use and large user community make it a great research tool for almost any project. To help accelerate the uptake of the Raspberry Pi by the scientific community, I provide detailed guidelines, recommendations and considerations, and 30+ step-by-step guides on a dedicated accompanying website (http://raspberrypi-guide.github.io). I hope this paper will help generate more awareness about the Raspberry Pi among scientists and thereby both fuel the democratisation of science and ultimately help advance our understanding of biology, from the micro- to the macro-scale.},
year = {2021}
}

@article{prinz2016a,
author = {Prinz, Anna C. B. and Taank, Vikas K. and Voegeli, Vincent and Walters, Eric L.},
title = {A novel nest-monitoring camera system using a {R}aspberry {P}i micro-computer},
journal = {Journal of Field Ornithology},
volume = {87},
number = {4},
pages = {427-435},
keywords = {Acorn Woodpeckers, cavity cameras, monitoring, nest monitoring, Pi NoIR, video},
doi = {https://doi.org/10.1111/jofo.12182},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jofo.12182},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/jofo.12182},
abstract = {Abstract The utility, availability, cost-effectiveness, and reliability of prefabricated video systems designed to monitor wildlife have lagged behind the unique and varied needs of many researchers. Many systems are limited by inflexible video settings, lack of adequate data storage, and cannot be programmed by the user. More sophisticated systems can be cost prohibitive, and the literature describing remote wildlife video monitoring has, for the most part, not incorporated advances in camera and computer technology. Here, we present details of a pilot study to design and construct a lower cost (US \$340) nest camera system to record the behavior of Acorn Woodpeckers (Melanerpes formicivorus) in artificial tree cavity nests. This system incorporates a Raspberry Pi micro-computer, Pi NoIR infrared camera, a wireless adapter to transmit video over the Internet, and Deka rechargeable gel batteries for power. We programmed the system to motion-sense, to record exclusively during daylight hours, and to automatically upload videos to the cloud over wireless Internet. The Raspberry Pi micro-computer does not require advanced programming or electrical engineering skills to build and configure and, because it is programmable, provides unprecedented flexibility for field researchers who wish to configure the system to the specific needs of their study.},
year = {2016}
}

@article{rico-guevara2017bring,
author = {Rico-Guevara, Alejandro and Mickley, James},
title = {Bring your own camera to the trap: An inexpensive, versatile, and portable triggering system tested on wild hummingbirds},
journal = {Ecology and Evolution},
volume = {7},
number = {13},
pages = {4592-4598},
keywords = {camera trap, field equipment, high-speed video, hummingbirds, remote cameras, video monitoring, video triggers},
doi = {https://doi.org/10.1002/ece3.3040},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.3040},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ece3.3040},
abstract = {Abstract The study of animals in the wild offers opportunities to collect relevant information on their natural behavior and abilities to perform ecologically relevant tasks. However, it also poses challenges such as accounting for observer effects, human sensory limitations, and the time intensiveness of this type of research. To meet these challenges, field biologists have deployed camera traps to remotely record animal behavior in the wild. Despite their ubiquity in research, many commercial camera traps have limitations, and the species and behavior of interest may present unique challenges. For example, no camera traps support high-speed video recording. We present a new and inexpensive camera trap system that increases versatility by separating the camera from the triggering mechanism. Our system design can pair with virtually any camera and allows for independent positioning of a variety of sensors, all while being low-cost, lightweight, weatherproof, and energy efficient. By using our specialized trigger and customized sensor configurations, many limitations of commercial camera traps can be overcome. We use this system to study hummingbird feeding behavior using high-speed video cameras to capture fast movements and multiple sensors placed away from the camera to detect small body sizes. While designed for hummingbirds, our application can be extended to any system where specialized camera or sensor features are required, or commercial camera traps are cost-prohibitive, allowing camera trap use in more research avenues and by more researchers.},
year = {2017}
}

@article{meek2012user,
title={User-based design specifications for the ultimate camera trap for wildlife research},
author={Meek, PD and Pittet, A},
journal={Wildlife Research},
volume={39},
number={8},
pages={649--660},
year={2012},
publisher={CSIRO Publishing}
}

@article{welbourne2016how,
author = {Welbourne, Dustin J. and Claridge, Andrew W. and Paull, David J. and Lambert, Andrew},
title = {How do passive infrared triggered camera traps operate and why does it matter? Breaking down common misconceptions},
journal = {Remote Sensing in Ecology and Conservation},
volume = {2},
number = {2},
pages = {77-83},
keywords = {Camera traps, emissivity, infrared, PIR, radiation, technical description},
doi = {https://doi.org/10.1002/rse2.20},
url = {https://zslpublications.onlinelibrary.wiley.com/doi/abs/10.1002/rse2.20},
eprint = {https://zslpublications.onlinelibrary.wiley.com/doi/pdf/10.1002/rse2.20},
abstract = {Abstract The use of passive infrared (PIR) triggered camera traps has dramatically increased in recent decades. Unfortunately, technical descriptions of how PIR triggered camera traps operate have not been sufficiently clear. Descriptions have often been ambiguous or misleading and in several cases are demonstrably wrong. Such descriptions have led to erroneous interpretations of camera trapping data. This short communication clarifies how PIR sensors operate. We clarify how infrared radiation is emitted and transmitted, and we describe the parts of the PIR sensor and how they detect infrared radiation and, by extension, fauna. Several problematic descriptions of PIR sensors are drawn on to highlight flawed descriptions and demonstrate where erroneous interpretations of camera trapping data occurred. By clarifying the language and the description of PIR triggered camera traps, this paper ensures that wildlife researchers and managers using camera traps will avoid flawed interpretations of their data. Avoiding flawed interpretations of data should reduce wasted effort and resources that would otherwise come about as researchers attempt to test flawed hypotheses. Furthermore, this paper provides a thorough technical reference for camera trapping practitioners, which is not present elsewhere in the wildlife research literature.},
year = {2016}
}

@article{rovero2013which,
journal={Hystrix, the Italian Journal of Mammalogy},
issn={0394-1914},
volume={24},
number={2},
year={2013},
title={Which camera trap type and how many do I need? A review of camera features and study designs for a range of wildlife research applications},
abstract={Automatically triggered cameras taking photographs or videos of passing animals (camera traps) have emerged over the last decade as one of the most powerful tool for wildlife research. In parallel, a wealth of camera trap systems and models has become commercially available, a phenomenon mainly driven by the increased use of camera traps by sport hunters. This has raised the need for developing criteria to choose the suitable camera trap model in relation to a range of factors, primarily the study aim, but also target species, habitat, trapping site, climate and any other aspect that affects camera performance. There is also fragmented information on the fundamentals of sampling designs that deploy camera trapping, such as number of sampling sites, spatial arrangement and sampling duration. In this review, we describe the relevant technological features of camera traps and propose a set of the key ones to be evaluated when choosing camera models. These features are camera specifications such as trigger speed, sensor sensitivity, detection zone, flash type and flash intensity, power autonomy, and related specifications. We then outline sampling design and camera features for the implementation of major camera trapping applications, specifically: (1) faunal inventories, (2) occupancy studies, (3) density estimation through Capture-Mark-Recapture and (4) density estimation through the Random Encounter Model. We also review a range of currently available models and stress the need for standardized testing of camera models that should be frequently updated and widely distributed. Finally we summarize the ultimate camera trap, as desired by wildlife biologists, and the current technological limitations of camera traps in relation to their potential for a number of emerging applications.},
author={Rovero, Francesco and Zimmermann, Fridolin and Berzi, Duccio and Meek, Paul},
pages={148--156},
doi={10.4404/hystrix-24.2-8789},
url={https://doi.org/10.4404/hystrix-24.2-8789}
}

@article{hobbs2017an,
    doi = {10.1371/journal.pone.0185026},
    author = {Hobbs, Michael T. AND Brehme, Cheryl S.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {An improved camera trap for amphibians, reptiles, small mammals, and large invertebrates},
    year = {2017},
    month = {10},
    volume = {12},
    url = {https://doi.org/10.1371/journal.pone.0185026},
    pages = {1-15},
    abstract = {Camera traps are valuable sampling tools commonly used to inventory and monitor wildlife communities but are challenged to reliably sample small animals. We introduce a novel active camera trap system enabling the reliable and efficient use of wildlife cameras for sampling small animals, particularly reptiles, amphibians, small mammals and large invertebrates. It surpasses the detection ability of commonly used passive infrared (PIR) cameras for this application and eliminates problems such as high rates of false triggers and high variability in detection rates among cameras and study locations. Our system, which employs a HALT trigger, is capable of coupling to digital PIR cameras and is designed for detecting small animals traversing small tunnels, narrow trails, small clearings and along walls or drift fencing.},
    number = {10},

}

@misc{hofmeyer2024private,
  author = {Hofmeyer, Sally and Cunningham, Susan},
  year={2024},
  month={Mar},
  howpublished = {personal communication}
  }

  @article{gula2010audio,
  title={An audio/video surveillance system for wildlife},
  author={Gula, Roman and Theuerkauf, J{\"o}rn and Rouys, Sophie and Legault, Andrew},
  journal={European Journal of Wildlife Research},
  volume={56},
  pages={803--807},
  year={2010},
  publisher={Springer}
}

@article{li2010design,
  title={Design and implementation of a sensor-based wireless camera system for continuous monitoring in assistive environments},
  author={Li, Nan and Yan, Bo and Chen, Guanling and Govindaswamy, Prabhu and Wang, Jie},
  journal={Personal and Ubiquitous Computing},
  volume={14},
  pages={499--510},
  year={2010},
  publisher={Springer}
}

@phdthesis{huynh2010study,
  title={Study of Wired and Wireless Data Transmissions},
  author={Huynh, Allan},
  year={2010},
  school={Link{\"o}ping University Electronic Press}
}

@inproceedings{adsumilli2002adaptive,
  title={Adaptive Wireless Video Communications: Challenges and Approaches},
  author={Adsumilli, Chowdary and Hu, Yu Hen},
  booktitle={Proceedings of International Workshop on Packet Video},
  pages={1--11},
  year={2002}
}

@inproceedings{peng2018plora,
  title={{PLoRa}: A passive long-range data network from ambient LoRa transmissions},
  author={Peng, Yao and Shangguan, Longfei and Hu, Yue and Qian, Yujie and Lin, Xianshang and Chen, Xiaojiang and Fang, Dingyi and Jamieson, Kyle},
  booktitle={Proceedings of the 2018 conference of the ACM special interest group on data communication},
  pages={147--160},
  year={2018}
} 

@article{swann2011evaluating,
  title={Evaluating types and features of camera traps in ecological studies: a guide for researchers},
  author={Swann, Don E and Kawanishi, Kae and Palmer, Jonathan},
  journal={Camera traps in animal ecology: Methods and analyses},
  pages={27--43},
  year={2011},
  publisher={Springer}
}

@article{aguiar-silva2017camera,
  title={Camera trapping at harpy eagle nests: interspecies interactions under predation risk},
  author={Aguiar-Silva, Francisca Helena and Jaudoin, Olivier and Sanaiotti, T{\^a}nia M and Seixas, Gl{\'a}ucia HF and Duleba, Samuel and Martins, Frederico D},
  journal={Journal of Raptor Research},
  volume={51},
  number={1},
  pages={72--78},
  year={2017},
  publisher={The Raptor Research Foundation, Inc.}
}

@article{glover2019camera,
  title={Camera-trapping version 3.0: current constraints and future priorities for development},
  author={Glover-Kapfer, Paul and Soto-Navarro, Carolina A and Wearn, Oliver R},
  journal={Remote Sensing in Ecology and Conservation},
  volume={5},
  number={3},
  pages={209--223},
  year={2019},
  publisher={Wiley Online Library}
}


@article{ribeiro-silva2018testing,
  title={Testing camera traps as a potential tool for detecting nest predation of birds in a tropical rainforest environment},
  author={Ribeiro-Silva, Lais and Perrella, Daniel F and Biagolini-Jr, Carlos H and Zima, Paulo VQ and Piratelli, Augusto J and Schlindwein, Marcelo N and Galetti Junior, Pedro M and Francisco, Mercival R},
  journal={Zoologia (Curitiba)},
  volume={35},
  pages={e14678},
  year={2018},
  publisher={SciELO Brasil}
}

@article{nazir2017wiseeye,
  title={WiseEye: Next generation expandable and programmable camera trap platform for wildlife research},
  author={Nazir, Sajid and Newey, Scott and Irvine, R Justin and Verdicchio, Fabio and Davidson, Paul and Fairhurst, Gorry and Wal, Ren{\'e} van der},
  journal={PLoS one},
  volume={12},
  number={1},
  pages={e0169758},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{green2020innovations,
  title={Innovations in camera trapping technology and approaches: The integration of citizen science and artificial intelligence},
  author={Green, Si{\^a}n E and Rees, Jonathan P and Stephens, Philip A and Hill, Russell A and Giordano, Anthony J},
  journal={Animals},
  volume={10},
  number={1},
  pages={132},
  year={2020},
  publisher={MDPI}
}

@article{ahumada2020wildlife,
  title={Wildlife insights: A platform to maximize the potential of camera trap and other passive sensor wildlife data for the planet},
  author={Ahumada, Jorge A and Fegraus, Eric and Birch, Tanya and Flores, Nicole and Kays, Roland and O’Brien, Timothy G and Palmer, Jonathan and Schuttler, Stephanie and Zhao, Jennifer Y and Jetz, Walter and others},
  journal={Environmental Conservation},
  volume={47},
  number={1},
  pages={1--6},
  year={2020},
  publisher={Cambridge University Press}
}

@book{meek2012introduction,
  title={An introduction to camera trapping for wildlife surveys in Australia},
  author={Meek, Paul D and Fleming, Peter and Ballard, Guy},
  year={2012},
  publisher={Invasive Animals Cooperative Research Centre Canberra, Australia}
}

@article{dewan2014alternative,
title = {Alternative power sources for remote sensors: A review},
journal = {Journal of Power Sources},
volume = {245},
pages = {129-143},
year = {2014},
issn = {0378-7753},
doi = {https://doi.org/10.1016/j.jpowsour.2013.06.081},
url = {https://www.sciencedirect.com/science/article/pii/S0378775313010884},
author = {Alim Dewan and Suat U. Ay and M. Nazmul Karim and Haluk Beyenal},
keywords = {Remote power, Renewable power, Wireless sensor, Environmental monitoring},
abstract = {The goal of this review is to assess renewable power sources as alternatives to the batteries traditionally used for remote environmental monitoring. In this review, we first discuss remote sensors and then we: 1) review the power requirements and traditionally used power sources for remote sensors, 2) describe the working principles of the renewable power sources used for powering remote sensors, 3) evaluate the challenges and potentials of the renewable power sources, and 4) review the power management systems developed for remote power generation and discuss how to use them to generate reliable power. In the description of each of the renewable power sources, we include the current status and future directions of the research. We believe that hybrid systems using more than a single renewable power source can provide more reliable renewable power. We conclude that renewable power sources have been demonstrated to be able to generate sufficient power for remote sensors. Because of the environmental risks and cost of operation associated with batteries, renewable energy sources will need to be used to power remote sensors in the near future.}
}

@ARTICLE{polonelli2020flexible,
  author={Polonelli, Tommaso and Qin, Yuan and Yeatman, Eric M. and Benini, Luca and Boyle, David},
  journal={IEEE Access}, 
  title={A Flexible, Low-Power Platform for UAV-Based Data Collection From Remote Sensors}, 
  year={2020},
  volume={8},
  number={},
  pages={164775-164785},
  keywords={Drones;Wireless sensor networks;Distance measurement;Wireless communication;Hardware;Monitoring;Autonomous vehicles;unmanned autonomous vehicles;unmanned aerial vehicles;radio navigation;wireless power transmission;wireless sensor networks;ultra wideband communication;printed circuits;open source hardware;open source software},
  doi={10.1109/ACCESS.2020.3021370}
  }

  @Article{callebaut2021art,
AUTHOR = {Callebaut, Gilles and Leenders, Guus and Van Mulders, Jarne and Ottoy, Geoffrey and De Strycker, Lieven and Van der Perre, Liesbet},
TITLE = {The Art of Designing Remote IoT Devices—Technologies and Strategies for a Long Battery Life},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {913},
URL = {https://www.mdpi.com/1424-8220/21/3/913},
PubMedID = {33572897},
ISSN = {1424-8220},
ABSTRACT = {Long-range wireless connectivity technologies for sensors and actuators open the door for a variety of new Internet of Things (IoT) applications. These technologies can be deployed to establish new monitoring capabilities and enhance efficiency of services in a rich diversity of domains. Low energy consumption is essential to enable battery-powered IoT nodes with a long autonomy. This paper explains the challenges posed by combining low-power and long-range connectivity. An energy breakdown demonstrates the dominance of transmit and sleep energy. The principles for achieving both low-power and wide-area are outlined, and the landscape of available networking technologies that are suited to connect remote IoT nodes is sketched. The typical anatomy of such a node is presented, and the subsystems are zoomed into. The art of designing remote IoT devices requires an application-oriented approach, where a meticulous design and smart operation are essential to grant a long battery life. In particular we demonstrate the importance of strategies such as “think before you talk” and “race to sleep”. As maintenance of IoT nodes is often cumbersome due to being deployed at hard to reach places, extending the battery life of these devices is critical. Moreover, the environmental impact of batteries further demonstrates the need for a longer battery life in order to reduce the number of batteries used.},
DOI = {10.3390/s21030913}
}

@misc{krejcar2012optimized, 
title={Optimized solar energy power supply for remote wireless sensors based on IEEE 802.15.4 Standard}, 
url={https://www.hindawi.com/journals/ijp/2012/305102/}, 
journal={International Journal of Photoenergy}, 
publisher={Hindawi}, 
author={Krejcar, Ondrej and Mahdal, Miroslav}, 
year={2012}, 
month={Dec}
} 

@INPROCEEDINGS{harikirshnan2017intelligent,
  author={Harikrishnan, R and Sivagami, P},
  booktitle={2017 International conference of Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={Intelligent power saving system using PIR sensors}, 
  year={2017},
  volume={2},
  number={},
  pages={573-577},
  keywords={Relays;Intelligent sensors;Monitoring;Sensor systems;Conferences;Aerospace electronics;PIR-passive infrared sensor;PIC microcontroller},
  doi={10.1109/ICECA.2017.8212729}
  }

@INPROCEEDINGS{harsha2020home,
  author={Harsha, B.K. and Kumar G.N., Naveen},
  booktitle={2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Home Automated Power Saving System Using PIR Sensor}, 
  year={2020},
  volume={},
  number={},
  pages={1117-1121},
  keywords={Switches;Fans;Buildings;Lighting;Batteries;Conferences;Robot sensing systems;Sensor;power saving;automatic energy saving system;electromechanical switch},
  doi={10.1109/ICIRCA48905.2020.9183050}}

